from __future__ import annotations

import os
import re
import subprocess
from typing import Any, Dict, List, Optional
import tempfile
from core.logger import logger


class DirsearchAgent:
 
    name = "Dirsearch Scanner"

    def __init__(
        self,
        wordlist: Optional[str] = None,
        threads: int = 20,
    ):
        self.wordlist = wordlist
        self.threads = threads

    def run(self, base_url: str) -> List[Dict[str, Any]]:
        if not isinstance(base_url, str) or not base_url.strip():
            logger.error("[dirsearch_agent] Invalid base_url")
            return []

        base_url = base_url.strip()
        if not base_url.startswith(("http://", "https://")):
            base_url = f"http://{base_url}"

        logger.info(f"[dirsearch_agent] Starting dirsearch scan for: {base_url}")

        # ä¿®æ­£ï¼šç§»é™¤æœ«å°¾çš„ ">"ï¼Œè¿™æ˜¯å‘½ä»¤è¡Œæç¤ºç¬¦ï¼Œä¸æ˜¯è·¯å¾„çš„ä¸€éƒ¨åˆ†
        dirsearch_dir = r"D:\web\å®æˆ˜æ¼æ´\Fuzzçˆ†ç ´\dirsearch"
        dirsearch_script = os.path.join(dirsearch_dir, "dirsearch.py")
        
        if not os.path.isfile(dirsearch_script):
            logger.error(f"[dirsearch_agent] dirsearch.py not found at: {dirsearch_script}")
            return []

        # ä½¿ç”¨å›ºå®šè¾“å‡ºæ–‡ä»¶ï¼ˆé¿å…ä¸´æ—¶è·¯å¾„ä¸­æ–‡é—®é¢˜ï¼‰
        output_file = os.path.join(dirsearch_dir, f"temp_out_{os.getpid()}.txt")

        try:
        
            cmd = [
                "python",
                "dirsearch.py",          # ç›¸å¯¹è·¯å¾„ï¼Œå› ä¸º cwd=dirsearch_dir
                "-u", base_url,
                "-w", "db/dicc.txt",     # ğŸ‘ˆ å…³é”®ï¼šå’Œä½  CMD é‡Œä¸€æ¨¡ä¸€æ ·ï¼
                "-e", "php,html,js,json,txt,xml",
                "--timeout=10",
                "-o", "temp_out.txt",    # è¾“å‡ºåˆ° cwd ä¸‹çš„ temp_out.txt
              #  f"--threads={self.threads}",
                "--cookie", "security=low; PHPSESSID=m0cfronvqiianfqrgmdoaovalk" #cookieéªŒè¯
            ]

            result = subprocess.run(
                cmd,
                cwd=dirsearch_dir,       # åœ¨æ­¤ç›®å½•ä¸‹è¿è¡Œï¼Œdb/dicc.txt æ‰æœ‰æ•ˆ
                capture_output=True,
                text=True,
                timeout=120,             # å»¶é•¿è¶…æ—¶
            )

            # è°ƒè¯•ä¿¡æ¯ï¼ˆä¸´æ—¶å¼€å¯ï¼‰
            if result.returncode != 0:
                logger.warning(f"[dirsearch_agent] Dirsearch exited with code {result.returncode}")
                logger.warning(f"[dirsearch_agent] STDERR: {result.stderr.strip()}")

            # è¯»å–è¾“å‡ºæ–‡ä»¶ï¼ˆåœ¨ dirsearch_dir ä¸‹ï¼‰
            output_path = os.path.join(dirsearch_dir, "temp_out.txt")
            discovered_urls = []

            if os.path.isfile(output_path) and os.path.getsize(output_path) > 0:
                try:
                    with open(output_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        lines = content.splitlines()
                    logger.info(f"[dirsearch_agent] Read {len(lines)} lines from temp_out.txt")
                except Exception as e:
                    logger.warning(f"[dirsearch_agent] Failed to read output file: {e}")
                    lines = []
            else:
                logger.warning("[dirsearch_agent] Output file not found or empty, falling back to stdout/stderr")
                lines = (result.stdout + "\n" + result.stderr).splitlines()

            # è§£æ dirsearch è¾“å‡º - æ”¯æŒå¤šç§æ ¼å¼
            ansi_escape = re.compile(r'\x1B[@-_][0-?]*[ -/]*[@-~]')
            
            # æ¨¡å¼1: æ ‡å‡†æ ¼å¼ "200   512B   http://target.com/login.php"
            pattern1 = re.compile(r"(\d{3})\s+\d+[BKMG]?\s+(https?://[^\s]+)")
            # æ¨¡å¼2: ç®€åŒ–æ ¼å¼ "200 http://target.com/login.php"
            pattern2 = re.compile(r"(\d{3})\s+(https?://[^\s]+)")
            # æ¨¡å¼3: JSON æ ¼å¼ï¼ˆå¦‚æœ dirsearch è¾“å‡º JSONï¼‰
            # æ¨¡å¼4: ä»… URL è¡Œï¼ˆå¦‚æœçŠ¶æ€ç åœ¨å…¶ä»–åœ°æ–¹ï¼‰
            pattern4 = re.compile(r"(https?://[^\s]+)")

            seen_urls = set()  # ç”¨äºå»é‡ï¼Œä½†ä¿ç•™æ‰€æœ‰çŠ¶æ€ç ä¿¡æ¯

            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if not line:
                    continue
                
                # ç§»é™¤ ANSI è½¬ä¹‰ç 
                clean_line = ansi_escape.sub('', line)
                
                # å°è¯•åŒ¹é…æ¨¡å¼1ï¼ˆæœ€å¸¸è§ï¼‰
                match = pattern1.search(clean_line)
                if match:
                    status_code = int(match.group(1))
                    url = match.group(2).strip()
                    if status_code in (200, 403):
                        url_key = url.lower()
                        if url_key not in seen_urls:
                            seen_urls.add(url_key)
                            discovered_urls.append({"url": url, "status": status_code})
                            logger.debug(f"[dirsearch_agent] Matched URL (pattern1): {url} (status: {status_code})")
                    continue
                
                # å°è¯•åŒ¹é…æ¨¡å¼2
                match = pattern2.search(clean_line)
                if match:
                    status_code = int(match.group(1))
                    url = match.group(2).strip()
                    if status_code in (200, 403):
                        url_key = url.lower()
                        if url_key not in seen_urls:
                            seen_urls.add(url_key)
                            discovered_urls.append({"url": url, "status": status_code})
                            logger.debug(f"[dirsearch_agent] Matched URL (pattern2): {url} (status: {status_code})")
                    continue
                
                # å¦‚æœè¡Œä¸­åŒ…å« URL ä½†æ²¡æœ‰åŒ¹é…åˆ°çŠ¶æ€ç ï¼Œå°è¯•æå– URLï¼ˆå¯èƒ½çŠ¶æ€ç åœ¨åˆ«å¤„ï¼‰
                if "http://" in clean_line or "https://" in clean_line:
                    url_match = pattern4.search(clean_line)
                    if url_match:
                        url = url_match.group(1).strip()
                        # å°è¯•ä»è¡Œä¸­æå–çŠ¶æ€ç ï¼ˆå¯èƒ½åœ¨ URL å‰é¢æˆ–åé¢ï¼‰
                        status_match = re.search(r'\b(200|403)\b', clean_line)
                        if status_match:
                            status_code = int(status_match.group(1))
                            url_key = url.lower()
                            if url_key not in seen_urls:
                                seen_urls.add(url_key)
                                discovered_urls.append({"url": url, "status": status_code})
                                logger.debug(f"[dirsearch_agent] Matched URL (pattern4): {url} (status: {status_code})")

            # æŒ‰ç”¨æˆ·è¦æ±‚ï¼šä¸åšå»é‡ï¼Œä¹Ÿä¸åˆ é™¤è¾“å‡ºæ–‡ä»¶ï¼Œå®Œæ•´ä¿ç•™æ‰«æç»“æœ
            logger.info(f"[dirsearch_agent] Found {len(discovered_urls)} interesting paths (200/403)")
            return discovered_urls
        except Exception as e:
            logger.error(f"[dirsearch_agent] Unexpected error during dirsearch scan: {e}", exc_info=True)
            return []