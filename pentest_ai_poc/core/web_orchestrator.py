from __future__ import annotations

from dataclasses import asdict, dataclass
from typing import Any, Dict, List
from urllib.parse import urlparse

from core.agents import AgentResult
from core.logger import logger
from plugins.fingerprinter import FingerprintResult, fingerprint_url
from subagents.dirsearch_agent import DirsearchAgent
from subagents.parameter_fuzzer import ParameterFuzzerAgent
from subagents.sqli_agent import SQLiAgent
from subagents.xss_agent import XSSAgent
from core.report_generator import generate_standard_vuln_report

@dataclass
class MultiAgentResult:
    url: str
    target: str
    fingerprint: FingerprintResult
    agent_results: List[AgentResult]
    reports: List[str]  # 标准格式报告列表（每个成功发现的漏洞一份报告）
    report_filename: str


class WebOrchestrator:
    """
    多智能体 Web 渗透测试 Orchestrator：
    1. 启动 Dirsearch 扫描发现路径
    2. 分析每个 URL 的漏洞可能性（基于规则匹配）
    3. 智能分发任务给对应的功能子 AI（SQLi / XSS 等）
    4. 顺序调用子 AI（避免高并发 DoS）
    5. 汇总子 AI 生成的报告
    注意：不再调用 LLM 生成报告，只有子 AI 成功验证漏洞后才生成报告。
    """

    def __init__(self) -> None:
        pass

    def _analyze_url_for_vulns(self, url: str) -> List[str]:
        """
        基于 URL 路径关键词判断可能漏洞类型。

        参数:
            url: 目标 URL（如 "http://target.com/login.php?id=1"）

        返回:
            List[str]: 可能的漏洞类型列表，如 ["sqli", "xss"]
        """
        url_lower = url.lower()
        possible_agents: List[str] = []

        # SQL 注入可能性判断
        sql_indicators = [
            "login",
            "user",
            "id=",
            "admin",
            "account",
            "profile",
            "search",
            "query=",
            "select",
            ".php",
            ".asp",
            ".aspx",
        ]
        if any(indicator in url_lower for indicator in sql_indicators):
            possible_agents.append("sqli")

        # XSS 可能性判断
        xss_indicators = [
            "search",
            "q=",
            "callback=",
            "comment",
            "message",
            "input",
            "form",
            ".html",
            ".htm",
        ]
        if any(indicator in url_lower for indicator in xss_indicators):
            possible_agents.append("xss")

        # API 相关（可能同时存在 XSS 和 IDOR）
        api_indicators = ["api", ".json", "/v1/", "/v2/", "/api/"]
        if any(indicator in url_lower for indicator in api_indicators):
            possible_agents.append("xss")
            # 注意：IDOR 需要更复杂的逻辑判断，这里暂不实现

        # 文件上传可能性判断
        upload_indicators = ["upload", "file=", "attach"]
        if any(indicator in url_lower for indicator in upload_indicators):
            # 文件上传漏洞检测需要专门的 Agent，这里暂不实现
            pass

        # 去重
        return list(dict.fromkeys(possible_agents))

    def _should_test_url_without_params(self, url: str) -> bool:
        """
        判断即使没有发现参数，是否也应该测试该 URL。
        例如：URL 本身已经包含参数，或者路径暗示可能存在参数。
        """
        url_lower = url.lower()
        # 如果 URL 已经包含参数，应该测试
        if "?" in url:
            return True
        # 如果路径包含常见参数相关的关键词，也应该测试
        param_indicators = ["login", "search", "query", "api", "user", "admin"]
        if any(indicator in url_lower for indicator in param_indicators):
            return True
        return False


    def run_full(self, target: str) -> Dict[str, Any]:
        """
        多智能体 Web 渗透测试完整流程（支持 Dirsearch 扫描和智能任务分发）。

        参数:
            target: 目标（可以是 IP、域名或完整 URL）
                注意：如果传入包含 path/query 的 URL（如 example.com/login?id=1），
                会自动提取 host 部分构造干净的 base URL（如 http://example.com），
                因为 Dirsearch 会重新扫描路径。

        返回:
            结构化结果，供 Web UI 展示
        """
        logger.info(f"[web_orchestrator] Starting multi-agent workflow for target: {target}")

        # Step 1: 正确解析并构造 base URL（仅协议 + host + 可选端口）
        # 使用 urlparse 提取 host，丢弃 path/query，避免错误拼接
        parsed = urlparse(target)
        if parsed.scheme in {"http", "https"}:
            # 已有协议，提取 host（包含端口）
            host = parsed.netloc or parsed.hostname or target.split("/")[0]
            scheme = parsed.scheme
        else:
            # 无协议，假设为 host，默认使用 http
            host = target.split("/")[0].split("?")[0]  # 移除可能的 path/query
            scheme = "http"

        base_url = f"{scheme}://{host}"
        logger.info(f"[web_orchestrator] Constructed base URL: {base_url} (from input: {target})")

        # Step 2: 启动 Dirsearch 扫描
        dirsearch_agent = DirsearchAgent()
        discovered_urls = dirsearch_agent.run(base_url)

        # 防御性过滤：只处理 200/403 响应
        discovered_urls = [
            item
            for item in discovered_urls
            if isinstance(item, dict)
            and item.get("status") in (200, 403)
            and isinstance(item.get("url"), str)
        ]

        logger.info(
            f"[web_orchestrator] Dirsearch found {len(discovered_urls)} interesting URLs (200/403)"
        )

        # 调试：记录所有发现的 URL
        if discovered_urls:
            logger.info(f"[web_orchestrator] All discovered URLs:")
            for idx, item in enumerate(discovered_urls, 1):
                logger.info(f"[web_orchestrator]   {idx}. {item.get('url')} (status: {item.get('status')})")
        else:
            logger.warning("[web_orchestrator] No URLs discovered by Dirsearch, skipping vulnerability analysis")

        # Step 3: 参数模糊测试子 AI：由 ParameterFuzzerAgent 决定哪些 URL 需要 fuzz
        param_agent = ParameterFuzzerAgent()
        param_result = param_agent.run({"urls": discovered_urls})
        urls_to_test: List[str] = list(param_agent.urls_to_test or [])

        logger.info(
            f"[web_orchestrator] Parameter fuzzing agent selected {len(urls_to_test)} URLs for further testing"
        )

        # Step 4: 对每个带参数的 URL 进行漏洞分析和测试
        # 去重控制：每个 URL 每种类型只测一次
        tested: set[tuple[str, str]] = set()
        all_reports: List[str] = []
        potential_reports: List[str] = []  # 可能存在漏洞但未被工具确认的 URL 报告
        # 把参数模糊测试子 AI 的结果也纳入 agent_results，便于 UI 显示
        all_agent_results: List[AgentResult] = [param_result]
        all_report_filenames: List[str] = []

        total_test_urls = len(urls_to_test)
        logger.info(f"[web_orchestrator] Starting vulnerability analysis of {total_test_urls} URLs")

        for idx, test_url in enumerate(urls_to_test, 1):
            logger.info(
                f"[web_orchestrator] [{idx}/{total_test_urls}] Analyzing URL: {test_url}"
            )

            # 分析 URL 可能的漏洞类型
            possible_agents = self._analyze_url_for_vulns(test_url)

            if not possible_agents:
                logger.debug(
                    f"[web_orchestrator] No obvious vulnerability indicators for {test_url}"
                )
                continue

            logger.info(
                f"[web_orchestrator] URL {test_url} may have: {', '.join(possible_agents)}"
            )

            # Step 5: 调用对应子 AI（确保每个 URL 每种类型只测一次）
            if "sqli" in possible_agents and (test_url, "sqli") not in tested:
                tested.add((test_url, "sqli"))
                try:
                    sqli = SQLiAgent()
                    result = sqli.run({"url": test_url})
                    all_agent_results.append(result)

                    if result.success and result.vuln and result.report:
                        all_reports.append(result.report)
                        if result.report_filename:
                            all_report_filenames.append(result.report_filename)
                        logger.info(
                            f"[web_orchestrator] SQLiAgent found vulnerability in {test_url}"
                        )
                    else:
                        # 规则命中但未确认漏洞，生成“可能存在 SQL 注入”的 URL 报告
                        try:
                            brief = "基于 URL 路径和参数特征，疑似存在 SQL 注入风险，尚未通过自动化工具完全验证。"
                            details = (
                                "URL 中包含 login、id、sqli 等与数据查询相关的关键词，触发 SQL 注入疑似规则；"
                                "自动化工具本次未能确认漏洞（可能是过滤绕过、WAF、防护或需要更复杂的手工测试）；"
                                "建议结合业务逻辑使用手工测试或更深度的 tamper/布尔盲注/时间盲注等方式进一步确认。"
                            )
                            poc = "暂无自动化 PoC，仅将该 URL 标记为高优先级人工复查对象。"
                            potential_reports.append(
                                generate_standard_vuln_report(
                                    target_unit=host,
                                    vuln_type="可能存在SQL注入漏洞的url报告",
                                    url=test_url,
                                    brief_desc=brief,
                                    poc=poc,
                                    details=details,
                                )
                            )
                        except Exception as e:
                            logger.error(
                                f"[web_orchestrator] Failed to build potential SQLi report for {test_url}: {e}"
                            )
                except Exception as exc:
                    logger.error(f"[web_orchestrator] SQLiAgent failed for {test_url}: {exc}")

            if "xss" in possible_agents and (test_url, "xss") not in tested:
                tested.add((test_url, "xss"))
                try:
                    xss = XSSAgent()
                    result = xss.run({"url": test_url})
                    all_agent_results.append(result)

                    if result.success and result.vuln and result.report:
                        all_reports.append(result.report)
                        if result.report_filename:
                            all_report_filenames.append(result.report_filename)
                        logger.info(
                            f"[web_orchestrator] XSSAgent found vulnerability in {test_url}"
                        )
                    else:
                        # 规则命中但未确认漏洞，生成“可能存在 XSS 漏洞”的 URL 报告
                        try:
                            brief = "基于 URL 路径、参数及可能存在的反射点，疑似存在 XSS 风险，尚未通过自动化工具完全验证。"
                            details = (
                                "URL 中包含 search、q、callback、comment 等与用户输入/输出相关的关键词，触发 XSS 疑似规则；"
                                "自动化脚本未观察到明显的 payload 回显或编码绕过效果，可能需要构造更复杂的上下文相关 payload；"
                                "建议结合浏览器调试和手工构造多种 XSS payload（如事件属性、DOM-based XSS 等）进一步确认。"
                            )
                            poc = "暂无自动化 PoC，仅将该 URL 标记为中高优先级人工复查对象。"
                            potential_reports.append(
                                generate_standard_vuln_report(
                                    target_unit=host,
                                    vuln_type="可能存在XSS漏洞的url报告",
                                    url=test_url,
                                    brief_desc=brief,
                                    poc=poc,
                                    details=details,
                                )
                            )
                        except Exception as e:
                            logger.error(
                                f"[web_orchestrator] Failed to build potential XSS report for {test_url}: {e}"
                            )
                except Exception as exc:
                    logger.error(f"[web_orchestrator] XSSAgent failed for {test_url}: {exc}")

        # Step 5: 生成汇总报告文本（用于 Web UI 显示）
        # 每个漏洞/可疑 URL 一份独立报告，用分隔符分隔
        combined_reports: List[str] = []
        combined_reports.extend(all_reports)
        combined_reports.extend(potential_reports)

        if combined_reports:
            if len(combined_reports) == 1:
                ai_report = combined_reports[0]
            else:
                ai_report = "\n\n" + "=" * 80 + "\n\n".join(combined_reports)
        else:
            ai_report = "本次扫描未发现漏洞。所有子 AI 均未确认到明确的漏洞，也未标记可疑 URL。"

        # 获取第一个报告文件名（如果有多个，使用第一个）
        report_filename = all_report_filenames[0] if all_report_filenames else ""

        # 从 base_url 提取"目标"显示用（用于 Web UI）
        display_target = host

        # 执行指纹识别（用于显示技术栈信息）
        fp = fingerprint_url(base_url)

        # 兼容现有 Web UI 字段命名
        return {
            "url": base_url,
            "target": display_target,
            "tech_stack": fp.tech_stack,
            "has_form": fp.has_form,
            "enabled_agents": ["Dirsearch Scanner", "Parameter Fuzzer", "SQLi Tester", "XSS Tester"],
            "agent_results": [asdict(r) for r in all_agent_results],
            "report": ai_report,  # 标准格式报告（或多个报告的拼接）
            "report_filename": report_filename,
            "discovered_urls": discovered_urls,  # 新增：Dirsearch 发现的 URL 列表
            # 兼容历史字段（对 Web 流程可为空）
            "raw_nmap_output": "",
            "services": [],
            "cve_matches": {},
        }