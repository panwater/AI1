from __future__ import annotations

from dataclasses import asdict, dataclass
from typing import Any, Dict, List
from urllib.parse import urlparse

from core.agent import AIAgent
from core.agents import AgentResult
from core.logger import LOG_FILE, logger
from plugins.fingerprinter import FingerprintResult, fingerprint_url
from subagents.dirsearch_agent import DirsearchAgent
from subagents.parameter_fuzzer import ParameterFuzzerAgent
from subagents.sqli_agent import SQLiAgent
from subagents.xss_agent import XSSAgent
from core.report_generator import generate_standard_vuln_report, save_ai_report_to_file

@dataclass
class MultiAgentResult:
    url: str
    target: str
    fingerprint: FingerprintResult
    agent_results: List[AgentResult]
    reports: List[str]  # 标准格式报告列表（每个成功发现的漏洞一份报告）
    report_filename: str


class WebOrchestrator:
    """
    多智能体 Web 渗透测试 Orchestrator：
    1. 启动 Dirsearch 扫描发现路径
    2. 分析每个 URL 的漏洞可能性（基于规则匹配）
    3. 智能分发任务给对应的功能子 AI（SQLi / XSS 等）
    4. 顺序调用子 AI（避免高并发 DoS）
    5. 汇总子 AI 生成的报告
    注意：不再调用 LLM 生成报告，只有子 AI 成功验证漏洞后才生成报告。
    """

    def __init__(self) -> None:
        pass

    def _analyze_url_for_vulns(self, url: str) -> List[str]:
        """
        基于 URL 路径关键词判断可能漏洞类型。

        参数:
            url: 目标 URL（如 "http://target.com/login.php?id=1"）

        返回:
            List[str]: 可能的漏洞类型列表，如 ["sqli", "xss"]
        """
        url_lower = url.lower()
        possible_agents: List[str] = []

        # SQL 注入可能性判断
        sql_indicators = [
            "login",
            "user",
            "id=",
            "admin",
            "account",
            "profile",
            "search",
            "query=",
            "select",
            ".php",
            ".asp",
            ".aspx",
        ]
        if any(indicator in url_lower for indicator in sql_indicators):
            possible_agents.append("sqli")

        # XSS 可能性判断
        xss_indicators = [
            "search",
            "q=",
            "callback=",
            "comment",
            "message",
            "input",
            "form",
            ".html",
            ".htm",
        ]
        if any(indicator in url_lower for indicator in xss_indicators):
            possible_agents.append("xss")

        # API 相关（可能同时存在 XSS 和 IDOR）
        api_indicators = ["api", ".json", "/v1/", "/v2/", "/api/"]
        if any(indicator in url_lower for indicator in api_indicators):
            possible_agents.append("xss")
            # 注意：IDOR 需要更复杂的逻辑判断，这里暂不实现

        # 文件上传可能性判断
        upload_indicators = ["upload", "file=", "attach"]
        if any(indicator in url_lower for indicator in upload_indicators):
            # 文件上传漏洞检测需要专门的 Agent，这里暂不实现
            pass

        # 去重
        return list(dict.fromkeys(possible_agents))

    def _should_test_url_without_params(self, url: str) -> bool:
        """
        判断即使没有发现参数，是否也应该测试该 URL。
        例如：URL 本身已经包含参数，或者路径暗示可能存在参数。
        """
        url_lower = url.lower()
        # 如果 URL 已经包含参数，应该测试
        if "?" in url:
            return True
        # 如果路径包含常见参数相关的关键词，也应该测试
        param_indicators = ["login", "search", "query", "api", "user", "admin"]
        if any(indicator in url_lower for indicator in param_indicators):
            return True
        return False


    def run_full(self, target: str) -> Dict[str, Any]:
        """
        多智能体 Web 渗透测试完整流程（支持 Dirsearch 扫描和智能任务分发）。

        参数:
            target: 目标（可以是 IP、域名或完整 URL）
                注意：如果传入包含 path/query 的 URL（如 example.com/login?id=1），
                会自动提取 host 部分构造干净的 base URL（如 http://example.com），
                因为 Dirsearch 会重新扫描路径。

        返回:
            结构化结果，供 Web UI 展示
        """
        logger.info(f"[web_orchestrator] Starting multi-agent workflow for target: {target}")

        # Step 1: 正确解析并构造 base URL（仅协议 + host + 可选端口）
        # 使用 urlparse 提取 host，丢弃 path/query，避免错误拼接
        parsed = urlparse(target)
        if parsed.scheme in {"http", "https"}:
            # 已有协议，提取 host（包含端口）
            host = parsed.netloc or parsed.hostname or target.split("/")[0]
            scheme = parsed.scheme
        else:
            # 无协议，假设为 host，默认使用 http
            host = target.split("/")[0].split("?")[0]  # 移除可能的 path/query
            scheme = "http"

        base_url = f"{scheme}://{host}"
        logger.info(f"[web_orchestrator] Constructed base URL: {base_url} (from input: {target})")

        # Step 2: 启动 Dirsearch 扫描
        dirsearch_agent = DirsearchAgent()
        discovered_urls = dirsearch_agent.run(base_url)

        # 防御性过滤：只处理 200/403 响应
        discovered_urls = [
            item
            for item in discovered_urls
            if isinstance(item, dict)
            and item.get("status") in (200, 403)
            and isinstance(item.get("url"), str)
        ]

        logger.info(
            f"[web_orchestrator] Dirsearch found {len(discovered_urls)} interesting URLs (200/403)"
        )

        # 调试：记录所有发现的 URL
        if discovered_urls:
            logger.info(f"[web_orchestrator] All discovered URLs:")
            for idx, item in enumerate(discovered_urls, 1):
                logger.info(f"[web_orchestrator]   {idx}. {item.get('url')} (status: {item.get('status')})")
        else:
            logger.warning("[web_orchestrator] No URLs discovered by Dirsearch, skipping vulnerability analysis")

        # Step 3: 参数模糊测试子 AI：由 ParameterFuzzerAgent 决定哪些 URL 需要 fuzz
        param_agent = ParameterFuzzerAgent()
        param_result = param_agent.run({"urls": discovered_urls})
        urls_to_test: List[str] = list(param_agent.urls_to_test or [])

        logger.info(
            f"[web_orchestrator] Parameter fuzzing agent selected {len(urls_to_test)} URLs for further testing"
        )

        # Step 4: 对每个带参数的 URL 进行漏洞分析和测试
        # 去重控制：每个 URL 每种类型只测一次
        tested: set[tuple[str, str]] = set()
        all_reports: List[str] = []
        potential_reports: List[str] = []  # 可能存在漏洞但未被工具确认的 URL 报告
        # 把参数模糊测试子 AI 的结果也纳入 agent_results，便于 UI 显示
        all_agent_results: List[AgentResult] = [param_result]
        all_report_filenames: List[str] = []

        total_test_urls = len(urls_to_test)
        logger.info(f"[web_orchestrator] Starting vulnerability analysis of {total_test_urls} URLs")

        for idx, test_url in enumerate(urls_to_test, 1):
            logger.info(
                f"[web_orchestrator] [{idx}/{total_test_urls}] Analyzing URL: {test_url}"
            )

            # 分析 URL 可能的漏洞类型
            possible_agents = self._analyze_url_for_vulns(test_url)

            if not possible_agents:
                logger.debug(
                    f"[web_orchestrator] No obvious vulnerability indicators for {test_url}"
                )
                continue

            logger.info(
                f"[web_orchestrator] URL {test_url} may have: {', '.join(possible_agents)}"
            )

            # Step 5: 调用对应子 AI（确保每个 URL 每种类型只测一次）
            if "sqli" in possible_agents and (test_url, "sqli") not in tested:
                tested.add((test_url, "sqli"))
                try:
                    sqli = SQLiAgent()
                    result = sqli.run({"url": test_url})
                    all_agent_results.append(result)

                    if result.success and result.vuln and result.report:
                        all_reports.append(result.report)
                        if result.report_filename:
                            all_report_filenames.append(result.report_filename)
                        logger.info(
                            f"[web_orchestrator] SQLiAgent found vulnerability in {test_url}"
                        )
                    else:
                        # 规则命中但未确认漏洞，生成“可能存在 SQL 注入”的 URL 报告
                        try:
                            brief = "基于 URL 路径和参数特征，疑似存在 SQL 注入风险，尚未通过自动化工具完全验证。"
                            details = (
                                "URL 中包含 login、id、sqli 等与数据查询相关的关键词，触发 SQL 注入疑似规则；"
                                "自动化工具本次未能确认漏洞（可能是过滤绕过、WAF、防护或需要更复杂的手工测试）；"
                                "建议结合业务逻辑使用手工测试或更深度的 tamper/布尔盲注/时间盲注等方式进一步确认。"
                            )
                            poc = "暂无自动化 PoC，仅将该 URL 标记为高优先级人工复查对象。"
                            potential_reports.append(
                                generate_standard_vuln_report(
                                    target_unit=host,
                                    vuln_type="可能存在SQL注入漏洞的url报告",
                                    url=test_url,
                                    brief_desc=brief,
                                    poc=poc,
                                    details=details,
                                )
                            )
                        except Exception as e:
                            logger.error(
                                f"[web_orchestrator] Failed to build potential SQLi report for {test_url}: {e}"
                            )
                except Exception as exc:
                    logger.error(f"[web_orchestrator] SQLiAgent failed for {test_url}: {exc}")

            if "xss" in possible_agents and (test_url, "xss") not in tested:
                tested.add((test_url, "xss"))
                try:
                    xss = XSSAgent()
                    result = xss.run({"url": test_url})
                    all_agent_results.append(result)

                    if result.success and result.vuln and result.report:
                        all_reports.append(result.report)
                        if result.report_filename:
                            all_report_filenames.append(result.report_filename)
                        logger.info(
                            f"[web_orchestrator] XSSAgent found vulnerability in {test_url}"
                        )
                    else:
                        # 规则命中但未确认漏洞，生成“可能存在 XSS 漏洞”的 URL 报告
                        try:
                            brief = "基于 URL 路径、参数及可能存在的反射点，疑似存在 XSS 风险，尚未通过自动化工具完全验证。"
                            details = (
                                "URL 中包含 search、q、callback、comment 等与用户输入/输出相关的关键词，触发 XSS 疑似规则；"
                                "自动化脚本未观察到明显的 payload 回显或编码绕过效果，可能需要构造更复杂的上下文相关 payload；"
                                "建议结合浏览器调试和手工构造多种 XSS payload（如事件属性、DOM-based XSS 等）进一步确认。"
                            )
                            poc = "暂无自动化 PoC，仅将该 URL 标记为中高优先级人工复查对象。"
                            potential_reports.append(
                                generate_standard_vuln_report(
                                    target_unit=host,
                                    vuln_type="可能存在XSS漏洞的url报告",
                                    url=test_url,
                                    brief_desc=brief,
                                    poc=poc,
                                    details=details,
                                )
                            )
                        except Exception as e:
                            logger.error(
                                f"[web_orchestrator] Failed to build potential XSS report for {test_url}: {e}"
                            )
                except Exception as exc:
                    logger.error(f"[web_orchestrator] XSSAgent failed for {test_url}: {exc}")

        # Step 5: 生成基础汇总文本（供后续 AI 总结使用）
        # 每个漏洞/可疑 URL 一份独立报告，用分隔符分隔
        combined_reports: List[str] = []
        combined_reports.extend(all_reports)
        combined_reports.extend(potential_reports)

        if combined_reports:
            if len(combined_reports) == 1:
                base_report_text = combined_reports[0]
            else:
                base_report_text = "\n\n" + "=" * 80 + "\n\n".join(combined_reports)
        else:
            base_report_text = "本次扫描未发现明显漏洞，子 AI 未确认到明确的漏洞，也未标记可疑 URL。"

        # Step 6: 调用本地 Ollama（qwen3-coder:30b）生成“AI 专属渗透报告”
        # 额外整合：
        #   - 最后一次 Dirsearch 原始输出文件：D:\\web\\实战漏洞\\Fuzz爆破\\dirsearch\\temp_out.txt
        #   - ffuf 原始输出文件：D:\\web\\信息收集\\JS_Extender\\ffuf_2.0.0_windows_amd64\\test.txt
        #   - 当前应用日志片段：logs/app.log（LOG_FILE）
        dirsearch_out_path = r"D:\web\实战漏洞\Fuzz爆破\dirsearch\temp_out.txt"
        ffuf_out_path = r"D:\web\信息收集\JS_Extender\ffuf_2.0.0_windows_amd64\test.txt"

        def _read_file_safe(path: str, label: str, max_chars: int = 20000) -> str:
            try:
                with open(path, "r", encoding="utf-8", errors="ignore") as f:
                    content = f.read()
                if len(content) > max_chars:
                    return content[-max_chars:]
                return content
            except Exception as e:
                logger.warning(f"[web_orchestrator] Failed to read {label} file '{path}': {e}")
                return f"[{label}] 文件无法读取或不存在（{e}）"

        # 读取日志（只取末尾一段，避免太长）
        logs_tail = ""
        try:
            if LOG_FILE.exists():
                with open(LOG_FILE, "r", encoding="utf-8", errors="ignore") as f:
                    log_content = f.read()
                max_log_chars = 20000
                logs_tail = log_content[-max_log_chars:]
            else:
                logs_tail = "日志文件不存在。"
        except Exception as e:
            logs_tail = f"读取日志失败: {e}"

        dirsearch_raw = _read_file_safe(dirsearch_out_path, "Dirsearch 输出")
        ffuf_raw = _read_file_safe(ffuf_out_path, "ffuf 输出")

        # 构造给 qwen3-coder:30b 的综合提示词
        discovered_urls_text = "\n".join(
            f"- {item.get('status')} {item.get('url')}"
            for item in discovered_urls
            if isinstance(item, dict) and item.get("url")
        ) or "（无 Dirsearch 发现的 200/403 URL）"

        urls_to_test_text = "\n".join(f"- {u}" for u in urls_to_test) or "（参数模糊测试未选择任何 URL）"

        prompt = f"""
你是一名资深渗透测试工程师，现在需要基于多源扫描数据，为目标【{host}】生成一份**AI 专属渗透测试报告**。

【一、标准化漏洞报告（工具已验证或规则命中的结果）】
{base_report_text}

【二、Dirsearch 发现的 URL（200/403）】
{discovered_urls_text}

【三、参与深度测试的 URL 列表（ParameterFuzzer 选择）】
{urls_to_test_text}

【四、Dirsearch 原始输出（temp_out.txt）】
{dirsearch_raw}

【五、ffuf 原始输出（test.txt）】
{ffuf_raw}

【六、最新日志片段（logs/app.log 末尾部分）】
{logs_tail}

请严格用中文输出一份结构化的渗透测试总结报告，报告内容**完全由你根据以上信息自行撰写**，不要简单复制粘贴原始文本，包含但不限于：
1. 测试范围与资产概况（按 URL/目录维度整体描述）。
2. 已确认或高度疑似的漏洞列表：按漏洞类型分组，每条给出影响、成因分析和复现思路。
3. 重点关注但尚未自动验证成功的可疑 URL：
   - 结合 Dirsearch/ffuf/参数特征，分析这些 URL 可能存在的漏洞类型（例如 SQL 注入、XSS、逻辑缺陷、敏感信息泄露等）；
   - 明确指出这些 URL 是“未测出漏洞但存在较大风险”的对象，并解释风险理由。
4. 结合日志信息，归纳本次测试过程中的异常现象（例如频繁 403、WAF 痕迹、重定向行为等），分析这些现象对漏洞挖掘的影响。
5. 给出后续人工深度渗透的优先级建议（高/中/低），并列出对应的 URL 或路径。

输出格式建议使用 Markdown 小标题（如：## 一、测试概况、## 二、已确认/疑似漏洞 等），方便在前端直接展示。
"""

        ai_agent = AIAgent()
        ai_report = ai_agent.generate_report(prompt)

        # 为 AI 总结报告增加统一的目标头部，便于历史页面解析
        display_target = host
        ai_report_with_header = f"**目标**: {display_target}\n\n" + (ai_report or "AI 未能生成渗透测试总结报告。")

        # 保存 AI 总结报告到历史报告目录，供 /history 页面查看和下载
        ai_report_filename = ""
        try:
            ai_report_filename = save_ai_report_to_file(ai_report_with_header, display_target)
        except Exception as e:
            logger.error(f"[web_orchestrator] Failed to save AI summary report: {e}")

        # 如果 AI 报告保存失败，则退回到第一个漏洞验证报告文件名
        report_filename = ai_report_filename or (all_report_filenames[0] if all_report_filenames else "")

        # 执行指纹识别（用于显示技术栈信息）
        fp = fingerprint_url(base_url)

        # 兼容现有 Web UI 字段命名
        return {
            "url": base_url,
            "target": display_target,
            "tech_stack": fp.tech_stack,
            "has_form": fp.has_form,
            "enabled_agents": ["Dirsearch Scanner", "Parameter Fuzzer", "SQLi Tester", "XSS Tester"],
            "agent_results": [asdict(r) for r in all_agent_results],
            "report": ai_report_with_header,  # AI 专属渗透报告（带目标头部，方便历史查看）
            "report_filename": report_filename,
            "discovered_urls": discovered_urls,  # 新增：Dirsearch 发现的 URL 列表
            # 兼容历史字段（对 Web 流程可为空）
            "raw_nmap_output": "",
            "services": [],
            "cve_matches": {},
        }